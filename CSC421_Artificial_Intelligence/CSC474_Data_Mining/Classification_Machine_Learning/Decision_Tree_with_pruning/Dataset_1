import sklearn as sk
import numpy as np
from sklearn import tree
from sklearn import linear_model
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
import graphviz
import matplotlib.pyplot as plt


def main(): #plots created using Decision tree method
            #critierion: Gini Index and Entropy

    dataset = np.loadtxt("cleaned_processed.cleveland.data",delimiter=",")

    X = dataset[:, :-1]
    y = dataset[:, -1]

    training_gini_error = []
    test_gini_error = []
    training_entropy_error = []
    test_entropy_error = []

    stepsize = []

    for i in np.arange(0.1,0.9,0.01):
        stepsize.append(i)
    for item in stepsize:

        # split dataset into training set and test set
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=item, random_state=0)

        # create classifiers
        gini_dt = tree.DecisionTreeClassifier(max_depth=3, criterion='gini')
        entropy_dt = decision_tree = tree.DecisionTreeClassifier(max_depth=3, criterion='entropy')

        gini_clf = gini_dt.fit(X_train, y_train)
        entropy_clf = entropy_dt.fit(X_train, y_train)

        gini_y_pred = gini_clf.predict(X_test)
        gini_train_pred = gini_clf.predict(X_train)
        entropy_y_pred = entropy_clf.predict(X_test)
        entropy_train_pred = entropy_clf.predict(X_train)

        # error=1-accuracy
        training_gini_error.append((1.0 - metrics.accuracy_score(y_train, gini_train_pred)))
        test_gini_error.append((1.0 - metrics.accuracy_score(y_test, gini_y_pred)))
        training_entropy_error.append((1.0 - metrics.accuracy_score(y_train, entropy_train_pred)))
        test_entropy_error.append((1.0 - metrics.accuracy_score(y_test , entropy_y_pred)))

    # use matplotlib to get plot
    plt.plot(stepsize, training_gini_error, "b-", label = "Gini Training Error")
    plt.plot(stepsize, training_entropy_error, "g-", label="Entropy Training Error")
    plt.plot(stepsize, test_gini_error, "r-", label="Gini Test Error")
    plt.plot(stepsize, test_entropy_error, "y-", label="Entropy Test Error")
    plt.legend(loc='upper right')
    plt.title("Decision Tree Problem1")
    plt.xlabel("Stepsizes")
    plt.ylabel("Errors")
    plt.show()

if __name__ == "__main__":
    main()



